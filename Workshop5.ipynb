{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2WS-jKq18kwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27ab84b-20fa-410f-850b-59cb5c5ea5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "    Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "Dataset Tail:\n",
            "      Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "Dataset Info:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "Descriptive Stats:\n",
            "               Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n",
            "Iteration 0: Cost 23207584.144711904\n",
            "Iteration 100: Cost inf\n",
            "Iteration 200: Cost nan\n",
            "Iteration 300: Cost nan\n",
            "Iteration 400: Cost nan\n",
            "Iteration 500: Cost nan\n",
            "Iteration 600: Cost nan\n",
            "Iteration 700: Cost nan\n",
            "Iteration 800: Cost nan\n",
            "Iteration 900: Cost nan\n",
            "Optimal Weights: [nan nan nan]\n",
            "Final Cost: nan\n",
            "RMSE: nan\n",
            "R-Squared: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "<ipython-input-1-edf5d7f831f0>:42: RuntimeWarning: overflow encountered in square\n",
            "  cost = (1 / (2 * m)) * np.sum((predictions - Y) ** 2)\n",
            "<ipython-input-1-edf5d7f831f0>:57: RuntimeWarning: invalid value encountered in subtract\n",
            "  W -= alpha * gradients\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Data Understanding, Analysis, and Preparation\n",
        "def load_and_prepare_data(file_path):\n",
        "    \"\"\"\n",
        "    Load and prepare the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): Path to the CSV dataset file.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Feature and target data split into training and testing sets.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/Dataset/student.csv\")\n",
        "\n",
        "    # Observe the dataset\n",
        "    print(\"Dataset Head:\\n\", data.head())\n",
        "    print(\"Dataset Tail:\\n\", data.tail())\n",
        "    print(\"Dataset Info:\\n\")\n",
        "    data.info()\n",
        "    print(\"Descriptive Stats:\\n\", data.describe())\n",
        "\n",
        "    # Split into features (X) and target (Y)\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "# Step 2: Cost Function\n",
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Calculates Mean Squared Error (MSE)\n",
        "    \"\"\"\n",
        "    m = len(Y)\n",
        "    predictions = np.dot(X, W)\n",
        "    cost = (1 / (2 * m)) * np.sum((predictions - Y) ** 2)\n",
        "    return cost\n",
        "\n",
        "# Step 3: Gradient Descent\n",
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize weights.\n",
        "    \"\"\"\n",
        "    m = len(Y)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        predictions = np.dot(X, W)\n",
        "        loss = predictions - Y\n",
        "        gradients = (1 / m) * np.dot(X.T, loss)\n",
        "        W -= alpha * gradients\n",
        "\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}: Cost {cost}\")\n",
        "\n",
        "    return W, cost_history\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))\n",
        "\n",
        "def r2(Y, Y_pred):\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Step 5: Main Function\n",
        "def main():\n",
        "    # File path to the dataset\n",
        "    file_path = \"/content/drive/MyDrive/Dataset/medical_students_dataset.csv\"  # Update the correct file path\n",
        "\n",
        "    # Load and prepare data\n",
        "    X_train, X_test, Y_train, Y_test = load_and_prepare_data(file_path)\n",
        "\n",
        "    # Add bias term (intercept) to the feature matrix\n",
        "    X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "    X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "    # Initialize weights, learning rate, and iterations\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.01\n",
        "    iterations = 1000\n",
        "\n",
        "    # Perform gradient descent\n",
        "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "    # Make predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Evaluate the model\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Output results\n",
        "    print(\"Optimal Weights:\", W_optimal)\n",
        "    print(\"Final Cost:\", cost_history[-1])\n",
        "    print(\"RMSE:\", model_rmse)\n",
        "    print(\"R-Squared:\", model_r2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}