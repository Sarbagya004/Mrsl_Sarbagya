{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg-qYMaWnkVA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    ps = PorterStemmer()\n",
        "    text = [ps.stem(word) for word in text if word not in stopwords.words('english')]\n",
        "    return ' '.join(text)\n",
        "\n",
        "### PART 1: SENTIMENT ANALYSIS WITH NAIVE BAYES ###\n",
        "# Load IMDB Dataset (Assumed CSV format)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/IMDB Dataset.csv\")\n",
        "df['clean_text'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorization\n",
        "cv = CountVectorizer()\n",
        "X_train = cv.fit_transform(X_train).toarray()\n",
        "X_test = cv.transform(X_test).toarray()\n",
        "\n",
        "# Train Naive Bayes Model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(\"Naive Bayes Sentiment Analysis Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "### PART 2: FEATURE SELECTION WITH RFE ###\n",
        "# Load Breast Cancer Dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression Model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# Apply Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Selected Features\n",
        "selected_features = rfe.support_\n",
        "ranking = rfe.ranking_\n",
        "\n",
        "# Transform Data using Selected Features\n",
        "X_train_rfe = rfe.transform(X_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# Retrain Model on Selected Features\n",
        "model.fit(X_train_rfe, y_train)\n",
        "y_pred_rfe = model.predict(X_test_rfe)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "print(\"\\nFeature Selection with RFE Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfe))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rfe))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rfe))\n",
        "\n",
        "### PART 3: PIPELINE IMPLEMENTATION ###\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', RFE(estimator=LogisticRegression(max_iter=200), n_features_to_select=5)),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200, 300],\n",
        "    'classifier__max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model evaluation\n",
        "y_pred_grid = grid_search.best_estimator_.predict(X_test)\n",
        "print(\"\\nPipeline with Feature Selection Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_grid))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_grid))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_grid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lueRZ_mXpQW1",
        "outputId": "cbe5436d-e2b6-4993-f90b-9e214ce328d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    ps = PorterStemmer()\n",
        "    text = [ps.stem(word) for word in text if word not in stopwords.words('english')]\n",
        "    return ' '.join(text)\n",
        "\n",
        "### PART 1: SENTIMENT ANALYSIS WITH NAIVE BAYES ###\n",
        "# Load IMDB Dataset (Assumed CSV format)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dataset/IMDB Dataset.csv\")\n",
        "df['clean_text'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorization\n",
        "cv = CountVectorizer()\n",
        "X_train = cv.fit_transform(X_train).toarray()\n",
        "X_test = cv.transform(X_test).toarray()\n",
        "\n",
        "# Train Naive Bayes Model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(\"Naive Bayes Sentiment Analysis Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, nb_model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "### PART 2: FEATURE SELECTION ###\n",
        "# Load Breast Cancer Dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Univariate Feature Selection\n",
        "univariate_selector = SelectKBest(score_func=f_classif, k=5)\n",
        "X_train_uni = univariate_selector.fit_transform(X_train, y_train)\n",
        "X_test_uni = univariate_selector.transform(X_test)\n",
        "\n",
        "# Wrapper Method (RFE)\n",
        "model = LogisticRegression(max_iter=200)\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)\n",
        "rfe.fit(X_train, y_train)\n",
        "X_train_rfe = rfe.transform(X_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# Embedded Method (Lasso)\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_train, y_train)\n",
        "selected_features_embedded = np.where(lasso.coef_ != 0)[0]\n",
        "X_train_embedded = X_train[:, selected_features_embedded]\n",
        "X_test_embedded = X_test[:, selected_features_embedded]\n",
        "\n",
        "# Model Training and Evaluation\n",
        "model.fit(X_train_rfe, y_train)\n",
        "y_pred_rfe = model.predict(X_test_rfe)\n",
        "print(\"\\nFeature Selection with RFE Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfe))\n",
        "\n",
        "### PART 3: NAIVE BAYES FROM SCRATCH ###\n",
        "def train_naive_bayes(X, y):\n",
        "    vocab = set()\n",
        "    class_counts = {0: 0, 1: 0}\n",
        "    word_counts = {0: {}, 1: {}}\n",
        "\n",
        "    for text, label in zip(X, y):\n",
        "        words = text.split()\n",
        "        class_counts[label] += 1\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "            if word not in word_counts[label]:\n",
        "                word_counts[label][word] = 0\n",
        "            word_counts[label][word] += 1\n",
        "    return vocab, class_counts, word_counts\n",
        "\n",
        "# Train Naive Bayes Model from Scratch\n",
        "vocab, class_counts, word_counts = train_naive_bayes(df['clean_text'], df['sentiment'])\n",
        "\n",
        "print(\"Naive Bayes from Scratch Model Trained Successfully!\")\n"
      ],
      "metadata": {
        "id": "dDI-itLYrqvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}