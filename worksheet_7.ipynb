{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YAvVWbqXoH1f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Stopping conditions\n",
        "        if len(unique_classes) == 1:\n",
        "            return {'class': unique_classes[0]}\n",
        "        if num_samples == 0 or (self.max_depth and depth >= self.max_depth):\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        best_info_gain = -float('inf')\n",
        "        best_split = None\n",
        "\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "                left_y = y[left_mask]\n",
        "                right_y = y[right_mask]\n",
        "                info_gain = self._information_gain(y, left_y, right_y)\n",
        "                if info_gain > best_info_gain:\n",
        "                    best_info_gain = info_gain\n",
        "                    best_split = {'feature_idx': feature_idx, 'threshold': threshold,\n",
        "                                  'left_y': left_y, 'right_y': right_y}\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        left_tree = self._build_tree(X[best_split['left_y']], best_split['left_y'], depth + 1)\n",
        "        right_tree = self._build_tree(X[best_split['right_y']], best_split['right_y'], depth + 1)\n",
        "\n",
        "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
        "                'left_tree': left_tree, 'right_tree': right_tree}\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        parent_entropy = self._entropy(parent)\n",
        "        left_entropy = self._entropy(left)\n",
        "        right_entropy = self._entropy(right)\n",
        "        weighted_avg_entropy = (len(left) / len(parent)) * left_entropy + (len(right) / len(parent)) * right_entropy\n",
        "        return parent_entropy - weighted_avg_entropy\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        class_probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(class_probs * np.log2(class_probs + 1e-9))  # Added small epsilon\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_single(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if 'class' in tree:\n",
        "            return tree['class']\n",
        "        feature_val = x[tree['feature_idx']]\n",
        "        if feature_val <= tree['threshold']:\n",
        "            return self._predict_single(x, tree['left_tree'])\n",
        "        else:\n",
        "            return self._predict_single(x, tree['right_tree'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "qxWM-fn2oIwM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the custom decision tree\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz6KK5yLoRnr",
        "outputId": "a1c27993-8ed6-4bcb-c8bb-175f50a7fe59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Scikit-learn decision tree\n",
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAc-gZxvoT-o",
        "outputId": "9edc22d9-9cc6-4c8a-fe28-642018889df2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy Comparison:\")\n",
        "print(f\"Custom Decision Tree: {accuracy_custom:.4f}\")\n",
        "print(f\"Scikit-learn Decision Tree: {accuracy_sklearn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-cg0Pf7oXpy",
        "outputId": "77f53936-f904-4acf-b93c-113c2aa8cf04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "Custom Decision Tree: 0.8000\n",
            "Scikit-learn Decision Tree: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = load_wine()\n",
        "X_wine = wine.data\n",
        "y_wine = wine.target\n",
        "\n",
        "# Split into training and test sets (80% training, 20% test)\n",
        "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train_wine, y_train_wine)\n",
        "y_pred_dt = dt_classifier.predict(X_test_wine)\n",
        "f1_dt = f1_score(y_test_wine, y_pred_dt, average='weighted')\n",
        "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train_wine, y_train_wine)\n",
        "y_pred_rf = rf_classifier.predict(X_test_wine)\n",
        "f1_rf = f1_score(y_test_wine, y_pred_rf, average='weighted')\n",
        "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBmeGmY-oamF",
        "outputId": "df277205-e237-468b-ba1a-f5fcb9223c87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9440\n",
            "Random Forest F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Create a Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
        "grid_search.fit(X_train_wine, y_train_wine)\n",
        "\n",
        "# Best parameters and score\n",
        "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-validation Accuracy: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymogple4odSl",
        "outputId": "040b9ea4-131e-4d22-f059-6be07b15ddab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.5s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
            "Best Hyperparameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best Cross-validation Accuracy: 0.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load Wine dataset for regression (use a continuous target variable)\n",
        "# For this, we'll consider \"target\" as the regression target\n",
        "X_wine_reg = wine.data\n",
        "y_wine_reg = wine.target\n",
        "\n",
        "# Split into training and test sets (80% training, 20% test)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_wine_reg, y_wine_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train_reg, y_train_reg)\n",
        "y_pred_dt_reg = dt_regressor.predict(X_test_reg)\n",
        "mse_dt = mean_squared_error(y_test_reg, y_pred_dt_reg)\n",
        "print(f\"Decision Tree Regressor MSE: {mse_dt:.4f}\")\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train_reg, y_train_reg)\n",
        "y_pred_rf_reg = rf_regressor.predict(X_test_reg)\n",
        "mse_rf = mean_squared_error(y_test_reg, y_pred_rf_reg)\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n",
        "\n",
        "# Hyperparameter tuning using RandomizedSearchCV\n",
        "param_grid_reg = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=rf_reg, param_distributions=param_grid_reg, n_iter=10, cv=5, verbose=2)\n",
        "random_search.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Best parameters and score\n",
        "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
        "print(f\"Best Cross-validation MSE: {random_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Eksj92onnc",
        "outputId": "82009ae9-fef6-491a-a424-d5def3cc91ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor MSE: 0.1667\n",
            "Random Forest Regressor MSE: 0.0648\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.4s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END .max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
            "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'max_depth': None}\n",
            "Best Cross-validation MSE: 0.9231\n"
          ]
        }
      ]
    }
  ]
}